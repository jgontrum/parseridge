experiment:
  attention_reporter_path: /usit/abel/u1/jgontrum/projects/thesis_experiments/{experiment_name}/attention_energies/
  code_path: /usit/abel/u1/jgontrum/projects/thesis_experiments/{experiment_name}/code
  commit: 5ffe4dbf69164eab649fd7e87f8ed752d847517f
  csv_output_file: /usit/abel/u1/jgontrum/projects/thesis_experiments/{experiment_name}/results.csv
  experiment_group: exp2_post_lstm_relu_residual
  experiment_name: 190_exp2_post_lstm_relu_residual
  google_sheets_auth_path: /usit/abel/u1/jgontrum/projects/parseridge/google_sheets_auth.json
  google_sheets_id: 1VsZYFdCRFWE4Qeux80rIhwBW1E3uXJ924nRI3GejB7o
  log_file: /usit/abel/u1/jgontrum/projects/thesis_experiments/{experiment_name}/experiment.log
  model_save_path: ''
  python_bin: python
  repository: git@github.com:jgontrum/parseridge.git
  show_progress_bars: false
model:
  attention:
    configuration_encoder: sentence_query_attention
    normalization_function: softmax
    scale_key: 0
    scale_query: 0
    scale_value: 0
    scoring_function: concat
  corpus:
    dev_corpus: /usit/abel/u1/jgontrum/nobackup/treebank/ud-treebanks-v2.4/UD_English-EWT/en_ewt-ud-dev.conllu
    oov_probability: 0.0
    test_corpus: /usit/abel/u1/jgontrum/nobackup/treebank/ud-treebanks-v2.4/UD_English-EWT/en_ewt-ud-test.conllu
    token_dropout: 0.0
    train_corpus: /usit/abel/u1/jgontrum/nobackup/treebank/ud-treebanks-v2.4/UD_English-EWT/en_ewt-ud-train.conllu
  embeddings:
    embedding_size: 300
    embeddings_file: /usit/abel/u1/jgontrum/nobackup/embeddings/fasttext/crawl-300d-2M.vec
    embeddings_vendor: fasttext
    freeze_embeddings: true
  input_encoder:
    input_encoder_type: lstm
    lstm_dropout: 0.33
    lstm_hidden_size: 125
    lstm_layers: 2
  mlp:
    mlp_dropout: 0.25
    relation_mlp_activation: tanh
    relation_mlp_layers:
    - 100
    transition_mlp_activation: tanh
    transition_mlp_layers:
    - 100
  parsing:
    error_probability: 0.1
    margin_threshold: 1.0
    num_buffer: 1
    num_stack: 3
training:
  batch_size: 4
  device: cpu
  epochs: 50
  gradient_clipping: 5
  learning_rate: 0.001
  loss_function: MaxMargin
  seed: 123456
  update_frequency: 50
  weight_decay: 0.0
